{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Layer Neural Network Example\n",
    "\n",
    "Builds a simple neural network with Keras ([code](../examples/mnist/mnist0.py))\n",
    "\n",
    "### MNIST Dataset Overview\n",
    "\n",
    "The MNIST database is a large dataset of handwritten digits used for training image processing algorthms. This data set has 50,000 training example images, and 10,000 testing images. Each image has been flatted from an array of size (28,28) to a 1-D numpy array with 784 features (28 * 28). \n",
    "\n",
    "### Code Overview:\n",
    "1. Import libraries\n",
    "2. Import data for training and testing \n",
    "3. Define Model\n",
    "4. Define Loss function\n",
    "5. Define Training procedure\n",
    "6. Run Model code \n",
    "    a. Train model\n",
    "    b. Test model\n",
    "7. Plot accuracy of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Code\n",
    "\n",
    "import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import time \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set training and network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "epochs = 10\n",
    "\n",
    "# Network Parameters\n",
    "NUM_INPUTS = 784\n",
    "NUM_OUTPUTS = 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import mnist data and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dataset\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "x_train = x_train.reshape(-1, NUM_INPUTS)\n",
    "x_test = x_test.reshape (-1, NUM_INPUTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(NUM_OUTPUTS, activation='softmax', input_dim=NUM_INPUTS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define optimizer, loss\n",
    "Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.5057 - categorical_accuracy: 0.8695 - val_loss: 0.3161 - val_categorical_accuracy: 0.9150\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 5s 97us/sample - loss: 0.3179 - categorical_accuracy: 0.9117 - val_loss: 0.2841 - val_categorical_accuracy: 0.9209\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 5s 95us/sample - loss: 0.2929 - categorical_accuracy: 0.9184 - val_loss: 0.2752 - val_categorical_accuracy: 0.9243\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 5s 102us/sample - loss: 0.2817 - categorical_accuracy: 0.9210 - val_loss: 0.2711 - val_categorical_accuracy: 0.9249\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 5s 103us/sample - loss: 0.2735 - categorical_accuracy: 0.9233 - val_loss: 0.2708 - val_categorical_accuracy: 0.9259\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 5s 104us/sample - loss: 0.2686 - categorical_accuracy: 0.9240 - val_loss: 0.2650 - val_categorical_accuracy: 0.9270\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 5s 104us/sample - loss: 0.2637 - categorical_accuracy: 0.9263 - val_loss: 0.2653 - val_categorical_accuracy: 0.9268\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 5s 102us/sample - loss: 0.2607 - categorical_accuracy: 0.9268 - val_loss: 0.2633 - val_categorical_accuracy: 0.9282\n",
      "Epoch 9/10\n",
      "22528/48000 [=============>................] - ETA: 2s - loss: 0.2537 - categorical_accuracy: 0.9281"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=epochs, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Accuracy \n",
    "plt.plot(history.history[\"categorical_accuracy\"])\n",
    "plt.plot(history.history[\"val_categorical_accuracy\"])\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend([\"Train Accuracy\", \"Test Accuracy\"], loc=\"upper left\")\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
